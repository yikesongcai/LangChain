{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、字符串输出解析器 StrOutputParser",
   "id": "842767e542907aec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T08:59:36.034766Z",
     "start_time": "2026-01-09T08:59:05.971150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser, XMLOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1、获取大模型\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('DEEPSEEK_API_KEY')\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('DEEPSEEK_BASE_URL')\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI(model_name=\"deepseek-chat\")\n",
    "\n",
    "\n",
    "# 2、调用大模型\n",
    "\n",
    "response = chat_model.invoke(\"什么是大语言模型？\")\n",
    "print(response)\n",
    "print(type(response)) # AIMessage\n",
    "\n",
    "# 3、如何获取一个字符串的输出结果呢？\n",
    "# 方式1：自己调用输出结果的content\n",
    "\n",
    "# print(response.content)\n",
    "\n",
    "# 方式2：使用StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "str_response = parser.invoke(response)\n",
    "print(type(str_response))\n"
   ],
   "id": "368aa79663870eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='大语言模型（Large Language Model，LLM）是一种基于深度学习的人工智能模型，专门用于理解和生成人类语言。以下是它的核心特点解析：\\n\\n---\\n\\n### **核心定义**\\n大语言模型是一种**参数规模巨大**（通常达数十亿甚至万亿级别）的自然语言处理模型，通过在海量文本数据上训练，学习语言的统计规律、语义逻辑和知识关联，从而能够完成多种语言任务。\\n\\n---\\n\\n### **关键技术原理**\\n1. **架构基础**  \\n   主流大语言模型基于**Transformer架构**（如GPT系列、PaLM、LLaMA等），其核心是**自注意力机制**，能够并行处理文本并捕捉长距离依赖关系。\\n\\n2. **训练过程**  \\n   - **预训练**：在无标注的万亿级文本上学习，通过预测被掩盖的词或下一句，掌握语言通用模式。  \\n   - **微调**：使用指令数据或人类反馈优化，使模型更符合实际应用需求（如对话、问答）。\\n\\n3. **核心能力**  \\n   - **上下文理解**：支持长文本对话（如GPT-4上下文窗口达128K tokens）。  \\n   - **泛化性**：无需针对特定任务重新训练，通过提示（Prompt）即可适应新场景。  \\n   - **多语言与多模态**：部分模型可处理文本、图像、代码等多种信息。\\n\\n---\\n\\n### **典型应用场景**\\n- **智能对话**：ChatGPT、文心一言等交互式助手。  \\n- **内容生成**：写作、翻译、代码编程、创意文案。  \\n- **知识问答**：基于训练数据中的信息进行解答（需注意时效性）。  \\n- **工具集成**：通过插件调用搜索引擎、数据库等外部工具。\\n\\n---\\n\\n### **重要局限性**\\n1. **幻觉现象**：可能生成看似合理但实际错误的内容。  \\n2. **知识时效性**：训练数据截止后，无法获取新信息（需借助检索增强）。  \\n3. **计算成本**：训练与部署需巨大算力，能耗较高。  \\n4. **伦理风险**：可能生成偏见、有害内容，需通过对齐技术约束。\\n\\n---\\n\\n### **发展里程碑**\\n- **2018年**：GPT-1首次展示预训练+微调潜力。  \\n- **2020年**：GPT-3（1750亿参数）推动少样本学习突破。  \\n- **2022年至今**：ChatGPT引发普及浪潮，多模态、开源模型（如LLaMA）快速发展。\\n\\n---\\n\\n### **未来方向**\\n- **小型化与高效化**：降低部署成本（如模型压缩、蒸馏）。  \\n- **具身智能**：与物理世界交互（如机器人控制）。  \\n- **可信AI**：提升可解释性、减少偏见与安全风险。\\n\\n---\\n\\n大语言模型正推动人工智能向通用化发展，但其本质仍是基于概率的复杂模式匹配系统，而非具备人类认知的“智能体”。理解其原理与局限，有助于更有效地利用这一技术工具。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 634, 'prompt_tokens': 9, 'total_tokens': 643, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 9}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '2098875a-9e3e-4bd6-90f9-6a637d555e27', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019ba1fb-301c-7543-ab29-52f45bb2115d-0' usage_metadata={'input_tokens': 9, 'output_tokens': 634, 'total_tokens': 643, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2、JsonOutputParser : Json输出解析器\n",
    "\n",
    "方式1：用户通过提示词要求大模型返回Json格式"
   ],
   "id": "b36393d26de351d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T09:10:21.177381Z",
     "start_time": "2026-01-09T09:10:17.401809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个靠谱的{role}\"),\n",
    "        (\"human\",\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_prompt_template.invoke({\"role\":\"智能助手\",\"question\":\"Torch和NLP有什么区别？问题用q表示，答案用a表示，返回一个JSON格式的数据\"})\n",
    "\n",
    "response = chat_model.invoke(prompt)\n",
    "print(response)\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "id": "329fe540b1d94df1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\\n  \"q\": \"Torch和NLP有什么区别？\",\\n  \"a\": \"Torch是一个开源的机器学习框架，主要用于深度学习研究和应用；而NLP（自然语言处理）是人工智能的一个子领域，专注于让计算机理解、生成和处理人类语言。Torch可以作为实现NLP任务的工具之一，但两者本质不同：一个是技术框架，一个是研究领域。\"\\n}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 32, 'total_tokens': 113, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 32}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'ee07d159-d4de-4815-ab2b-67dcb475a77e', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019ba205-563e-7232-b740-f609cf9c21a4-0' usage_metadata={'input_tokens': 32, 'output_tokens': 81, 'total_tokens': 113, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "{'q': 'Torch和NLP有什么区别？', 'a': 'Torch是一个开源的机器学习框架，主要用于深度学习研究和应用；而NLP（自然语言处理）是人工智能的一个子领域，专注于让计算机理解、生成和处理人类语言。Torch可以作为实现NLP任务的工具之一，但两者本质不同：一个是技术框架，一个是研究领域。'}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "方式2：\n",
    "\n",
    "举例1："
   ],
   "id": "109b854fd22f0013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "parser = JsonOutputParser()\n",
    "print(parser.get_format_instructions())"
   ],
   "id": "c4b952b248dab098"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：",
   "id": "7bd464ccbc7d29d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T09:51:02.591870Z",
     "start_time": "2026-01-09T09:50:58.162165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "joke_query = \"告诉我一个笑话\"\n",
    "\n",
    "# 定义Json解析器\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "\n",
    "# 以PromptTemplate为例\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({\"question\":joke_query})\n",
    "response = chat_model.invoke(prompt)\n",
    "json_result = parser.invoke(response)\n",
    "print(json_result)"
   ],
   "id": "30d651b66c2b3da5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': '为什么程序员分不清万圣节和圣诞节？\\n因为 Oct 31 == Dec 25。', 'explanation': '这是一个程序员笑话，利用了进制转换的梗：八进制（Octal）的31等于十进制（Decimal）的25，所以Oct 31（10月31日，万圣节）在数值上等于Dec 25（12月25日，圣诞节）。'}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3、XMLOutputParser XML输出解析器\n",
    "\n",
    "举例1：自己在提示词模板中写明使用XML格式"
   ],
   "id": "58c6e170715c0cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "actor_query = \"周星驰的简短电影记录\"\n",
    "response = chat_model.invoke(f\"请生成{actor_query}的简短电影记录，将影片附在<movie></movie>标签中\")\n",
    "\n",
    "print(response.content)"
   ],
   "id": "6d15c37f1d3c02b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "举例2：",
   "id": "e392fa0255624b86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T10:47:25.103152Z",
     "start_time": "2026-01-09T10:47:17.102130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.导入相关包\n",
    "from langchain_core.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "\n",
    "# 2.初始化语言模型\n",
    "chat_model = ChatOpenAI(model=\"deepseek-chat\")\n",
    "\n",
    "# 3.测试模型的xml解析效果\n",
    "actor_query = \"生成汤姆·汉克斯的简短电影记录，使用中文回复\"\n",
    "\n",
    "# 4.定义XMLOutputParser对象\n",
    "\n",
    "parser = XMLOutputParser()\n",
    "\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "# 5.生成提示词模板\n",
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    template=\"回答用户的查询\\n 满足的格式为{format_instructions}\\n 问题为{question}\\n\",\n",
    ")\n",
    "\n",
    "prompt_template1 = prompt_template.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "prompt = prompt_template1.invoke({\"question\":actor_query})\n",
    "\n",
    "response = chat_model.invoke(prompt)\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "xml_result = parser.invoke(response)\n",
    "\n",
    "print(xml_result)"
   ],
   "id": "7f6c2663c682b181",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<汤姆·汉克斯电影记录>\n",
      "  <电影>\n",
      "    <片名>阿甘正传</片名>\n",
      "    <年份>1994</年份>\n",
      "    <简介>讲述智商不高的阿甘·甘普斯凭借纯真与执着，亲历美国20世纪诸多重大历史事件并影响他人的故事。</简介>\n",
      "  </电影>\n",
      "  <电影>\n",
      "    <片名>拯救大兵瑞恩</片名>\n",
      "    <年份>1998</年份>\n",
      "    <简介>二战期间，米勒上尉率领小队深入敌后，寻找并带回家中四兄弟仅存的士兵瑞恩。</简介>\n",
      "  </电影>\n",
      "  <电影>\n",
      "    <片名>荒岛余生</片名>\n",
      "    <年份>2000</年份>\n",
      "    <简介>联邦快递系统工程师查克·诺兰德在空难后被困荒岛，在极端环境中挣扎求生并寻找人生意义。</简介>\n",
      "  </电影>\n",
      "</汤姆·汉克斯电影记录>\n",
      "{'汤姆·汉克斯电影记录': [{'电影': [{'片名': '阿甘正传'}, {'年份': '1994'}, {'简介': '讲述智商不高的阿甘·甘普斯凭借纯真与执着，亲历美国20世纪诸多重大历史事件并影响他人的故事。'}]}, {'电影': [{'片名': '拯救大兵瑞恩'}, {'年份': '1998'}, {'简介': '二战期间，米勒上尉率领小队深入敌后，寻找并带回家中四兄弟仅存的士兵瑞恩。'}]}, {'电影': [{'片名': '荒岛余生'}, {'年份': '2000'}, {'简介': '联邦快递系统工程师查克·诺兰德在空难后被困荒岛，在极端环境中挣扎求生并寻找人生意义。'}]}]}\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
