{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1、获取大模型",
   "id": "2f98b3320b7afcea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T07:14:06.682007Z",
     "start_time": "2025-12-29T07:13:32.268875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv() # 加载当前目录下的 .env 文件\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('DEEPSEEK_API_KEY')\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv('DEEPSEEK_API_URL')\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"deepseek-chat\") # 默认使用 gpt-3.5-turbo\n",
    "\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ],
   "id": "b285dff9d5bc7994",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='大模型（Large Language Model，简称LLM）是指**参数量巨大、训练数据海量、计算资源消耗庞大的深度学习模型**，通常指基于Transformer架构的自然语言处理模型。以下是其核心特点的总结：\\n\\n---\\n\\n### **1. 核心特征**\\n- **参数量巨大**：通常包含**数十亿到数万亿**参数（例如GPT-3有1750亿参数，GPT-4达约1.8万亿）。\\n- **海量训练数据**：使用互联网规模的文本数据（如网页、书籍、论文等）进行训练。\\n- **强大泛化能力**：无需针对特定任务重新训练，即可通过提示（Prompt）完成多种任务（翻译、写作、代码生成等）。\\n- **涌现能力**：当模型规模超过临界点，会表现出小模型不具备的能力（如复杂推理、上下文学习）。\\n\\n---\\n\\n### **2. 关键技术原理**\\n- **Transformer架构**：依赖自注意力机制（Self-Attention）捕捉长距离依赖关系。\\n- **预训练+微调范式**：\\n  - **预训练**：通过无监督学习从海量文本中学习语言规律。\\n  - **微调/提示工程**：用少量标注数据或指令调整模型以适应具体任务。\\n- **缩放定律（Scaling Laws）**：模型性能随参数、数据、计算量的增加而可预测提升。\\n\\n---\\n\\n### **3. 典型代表模型**\\n- **GPT系列**（OpenAI）：生成式预训练模型，代表有ChatGPT、GPT-4。\\n- **BERT系列**（Google）：双向编码模型，适用于理解类任务。\\n- **Gemini**（Google）：多模态大模型，支持文本、图像、音频。\\n- **LLaMA系列**（Meta）：开源模型，推动社区发展（如Alpaca、Vicuna等衍生模型）。\\n- **Claude**（Anthropic）：注重安全性与对齐的对话模型。\\n- **国内模型**：百度文心一言、阿里通义千问、讯飞星火、智谱GLM等。\\n\\n---\\n\\n### **4. 应用场景**\\n- **内容生成**：文本创作、代码编写、营销文案。\\n- **智能问答**：客服助手、知识库问答。\\n- **多模态交互**：图像描述、视频分析、语音合成。\\n- **科学研究**：文献摘要、蛋白质结构预测、数学推理。\\n- **企业工具**：办公自动化、数据分析、教育培训。\\n\\n---\\n\\n### **5. 挑战与争议**\\n- **算力需求**：训练需万卡级GPU集群，成本高昂。\\n- **幻觉问题**：可能生成看似合理但不准确的内容。\\n- **安全与伦理**：偏见放大、滥用风险（虚假信息、网络攻击）。\\n- **能耗问题**：单次训练耗电相当于数百家庭年用电量。\\n\\n---\\n\\n### **6. 未来趋势**\\n- **小型化与高效化**：模型压缩、蒸馏技术（如小型专用模型）。\\n- **多模态融合**：统一处理文本、图像、音频、视频。\\n- **具身智能**：大模型与机器人、物理世界交互。\\n- **开源与生态**：降低使用门槛，推动行业应用创新。\\n\\n---\\n\\n### **简单比喻**\\n大模型像一个**博览群书的超级大脑**，通过海量数据学会了语言的深层规律，不仅能复现知识，还能组合创新，但它的“思考”本质是概率计算，仍需人类引导与纠偏。\\n\\n如果需要进一步了解某个具体模型或技术细节，可以随时告诉我！' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 738, 'prompt_tokens': 8, 'total_tokens': 746, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 8}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'e8e60364-713c-4071-8b0e-4860bddcf2b5', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b68f4-9927-7010-831a-9bef2c9b0b74-0' usage_metadata={'input_tokens': 8, 'output_tokens': 738, 'total_tokens': 746, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2、使用提示词模板",
   "id": "71973abd7a080973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-26T06:37:29.224031Z",
     "start_time": "2025-12-26T06:36:54.976840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是世界级的技术文档编写者\"),\n",
    "    (\"user\",\"{input}\") # {input}为变量\n",
    "])\n",
    "\n",
    "# 我们可以把prompt和具体llm的调用和在一起\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\":\"大模型中的LangChain是什么？\"})\n",
    "print(message)\n",
    "\n",
    "# print(type(message))"
   ],
   "id": "19d1e583b7800ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**LangChain** 是一个用于构建**基于大语言模型（LLM）的应用**的开源框架。它不是一个模型本身，而是一个强大的“工具箱”和“脚手架”，旨在帮助开发者更轻松、更高效地将大语言模型（如GPT-4、Llama等）连接到各种数据源，并构建出功能强大、可交互的应用程序。\\n\\n简单来说，LangChain解决了大模型应用中的几个核心难题：**数据连接、序列化调用、记忆能力和复杂任务分解**。\\n\\n### LangChain的核心价值与主要组件\\n\\n你可以把LangChain想象成连接大模型与现实世界应用的“桥梁”和“粘合剂”。它的主要组成部分包括：\\n\\n1. **组件与链**\\n    *   **组件**： 提供各种模块化工具，例如：\\n        *   **模型I/O**： 与不同LLM（OpenAI、Anthropic、开源模型等）和嵌入模型交互的统一接口。\\n        *   **数据连接**： 从文档（PDF、Word、网页）、数据库、API等加载、转换、查询和存储数据。核心是**检索增强生成**。\\n        *   **记忆**： 为对话或多次交互提供短期/长期记忆能力（如记住之前的聊天内容）。\\n        *   **代理**： LLM的“大脑”，可以决定调用哪些工具（如计算器、搜索引擎、数据库查询）来完成任务。\\n    *   **链**： 将多个组件（或链）按特定顺序组合起来，完成一个复杂任务。例如，“加载文档 -> 分割文本 -> 创建向量索引 -> 根据问题检索 -> 生成答案”就是一个典型的检索链。\\n\\n2. **检索增强生成**\\n    *   这是LangChain最核心的应用场景之一。它通过以下步骤解决大模型“知识陈旧”和“幻觉”问题：\\n        1.  将你的私有或最新数据（如公司文档、知识库）进行处理和向量化存储。\\n        2.  当用户提问时，先从你的数据中检索出最相关的信息片段。\\n        3.  将这些信息片段作为上下文，连同问题一起发送给大模型，让它生成基于这些可靠信息的答案。\\n    *   这样，模型就能回答其训练数据之外的最新或特定领域的问题。\\n\\n3. **代理**\\n    *   代理让LLM具备了**使用工具**的能力。开发者可以定义各种工具（如网络搜索、代码执行、数据库操作），代理会根据用户的问题，自主决定调用哪个工具、按什么顺序调用，以完成复杂任务（例如：“查一下今天北京的天气，然后用中文写一首关于这种天气的短诗”）。\\n\\n### 一个简单的类比\\n\\n*   **大语言模型**： 一个**知识渊博但“与世隔绝”的学者**。他无所不知，但知识止于训练数据，也无法直接获取外界最新信息或操作外部系统。\\n*   **LangChain**： 这位学者的**全能助理团队**。这个团队负责：\\n    *   为学者提供最新的报告和档案（**RAG**）。\\n    *   在学者思考时，帮他记录和回忆对话要点（**记忆**）。\\n    *   当学者需要实际行动时（比如计算、查资料、发邮件），助理团队会去执行这些具体任务，并把结果汇报给学者（**代理**）。\\n    *   将学者复杂的思考过程，分解成标准化的流程（**链**）。\\n\\n### 主要应用场景\\n\\n*   **智能问答系统**： 基于特定文档、知识库的问答机器人。\\n*   **聊天机器人**： 具备长期记忆和工具调用能力的复杂对话助手。\\n*   **内容总结与分析**： 自动分析长文档、多个数据源并生成报告。\\n*   **代码辅助工具**： 理解代码库、生成或解释代码。\\n*   **智能工作流自动化**： 将LLM作为决策中枢，串联起多个业务系统。\\n\\n### 总结\\n\\n**LangChain的本质是LLM的应用开发框架**。它通过模块化设计，极大地降低了将大语言模型集成到实际产品中的门槛，让开发者能够专注于构建逻辑和用户体验，而不必重复处理数据连接、流程编排等底层问题。随着大模型应用的普及，LangChain已成为该领域最受关注和使用的工具之一。\\n\\n如果你想开始使用，其官方文档提供了丰富的教程和示例。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 903, 'prompt_tokens': 18, 'total_tokens': 921, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 18}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '91beccc7-fb2c-4b27-b72e-25aed56a8130', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b595f-e345-74a3-b157-df1a8cf34e04-0' usage_metadata={'input_tokens': 18, 'output_tokens': 903, 'total_tokens': 921, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
